{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBI9IPBzW4XG",
        "outputId": "c5090a8c-b8e2-411a-85b0-10fbc25f8054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "X = np.array([[1, 2],\n",
        "              [2, 3],\n",
        "              [3, 4],\n",
        "              [4, 5],\n",
        "              [5, 6]])\n",
        "y = np.array([1, 1, 0, 0, 0])\n",
        "\n",
        "# Initialize AdaBoost Classifier\n",
        "clf = AdaBoostClassifier(n_estimators=50, learning_rate=0.1, random_state=42,\n",
        "                         algorithm='SAMME')\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X)\n",
        "\n",
        "def accuracy(y_test, y_pred):\n",
        "  return np.mean(y_test == y_pred)\n",
        "\n",
        "acc = accuracy(y, y_pred)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AdaBoostWithTreeStump Pseudocode\n",
        "\n",
        "## Class: `AdaBoostWithTreeStump`\n",
        "\n",
        "### Attributes:\n",
        "- `n_estimators`: Number of weak learners (tree stumps) to train.\n",
        "- `alphas`: List of alpha weights (contribution of each weak learner to the final prediction).\n",
        "- `models`: List of trained weak learners (tree stumps).\n",
        "\n",
        "---\n",
        "\n",
        "## Methods:\n",
        "\n",
        "### `__init__(n_estimators=50)`\n",
        "**Purpose:** Initialize the AdaBoost model with the specified number of weak learners.\n",
        "\n",
        "1. Set `self.n_estimators` to `n_estimators`.\n",
        "2. Initialize `self.alphas` as an empty list.\n",
        "3. Initialize `self.models` as an empty list.\n",
        "\n",
        "---\n",
        "\n",
        "### `fit(X, y)`\n",
        "**Purpose:** Train the AdaBoost model on the input data `X` and target labels `y`.\n",
        "\n",
        "1. Determine the number of samples `m = X.shape[0]`.\n",
        "2. Initialize sample weights:\n",
        "   - `weights = array of size m, each element = 1/m`.\n",
        "3. **For each estimator (from 1 to `n_estimators`)**:\n",
        "   - Train a weak learner (tree stump):\n",
        "     - Create a `DecisionTree` with `max_depth=1`.\n",
        "     - Fit the tree stump on `X` and `y` using the current weights.\n",
        "   - Predict labels for the current dataset:\n",
        "     - `predictions = stump.predict(X)`.\n",
        "   - Compute the weighted classification error:\n",
        "     - `error = sum(weights[i] for i where predictions[i] != y[i])`.\n",
        "   - Calculate the alpha value:\n",
        "     - If `error == 0`:\n",
        "       - `alpha = very large value (e.g., 1e10)`.\n",
        "     - Otherwise:\n",
        "       - `alpha = 0.5 * log((1 - error) / error)`.\n",
        "   - Append the alpha value to `self.alphas`.\n",
        "   - Add the trained stump to `self.models`.\n",
        "   - Update the sample weights:\n",
        "     - For each sample `i`:\n",
        "       - If `predictions[i] == y[i]`:\n",
        "         - `weights[i] *= exp(-alpha)`.\n",
        "       - Else:\n",
        "         - `weights[i] *= exp(alpha)`.\n",
        "     - Normalize the weights to ensure they sum to 1.\n",
        "   - Perform resampling based on updated weights:\n",
        "     - Compute cumulative weights for the current sample set.\n",
        "     - Draw `m` samples with replacement using the weights as probabilities.\n",
        "     - Update `X` and `y` to the resampled dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### `predict(X)`\n",
        "**Purpose:** Predict labels for the input data `X` using the trained AdaBoost model.\n",
        "\n",
        "1. Initialize predictions:\n",
        "   - `final_predictions = array of size len(X), filled with zeros`.\n",
        "2. **For each trained model (`stump`) and corresponding alpha (`alpha`)**:\n",
        "   - Predict the labels using the model:\n",
        "     - `predictions = stump.predict(X)`.\n",
        "   - Add the weighted predictions to `final_predictions`:\n",
        "     - `final_predictions += alpha * predictions`.\n",
        "3. Convert the final predictions to binary labels:\n",
        "   - Return `1` where `final_predictions > 0` and `0` otherwise.\n"
      ],
      "metadata": {
        "id": "rvnnNUWbw9kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None\n",
        "\n",
        "\n",
        "class DecisionTree:\n",
        "  def __init__(self, max_depth=3):\n",
        "    self.max_depth = max_depth\n",
        "    self.root = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.root = self._build_tree(X, y)\n",
        "\n",
        "  def _build_tree(self, X, y, depth=0):\n",
        "    n_samples, n_features = X.shape\n",
        "    n_labels = len(np.unique(y))\n",
        "\n",
        "    if(n_labels == 1 or self.max_depth is not None and depth >= self.max_depth):\n",
        "      leaf_value = self._most_common_label(y)\n",
        "      return Node(value=leaf_value)\n",
        "\n",
        "    best_feature, best_threshold = self._best_split(X, y)\n",
        "\n",
        "    left_idxs , right_idxs = self._split(X[:, best_feature], best_threshold)\n",
        "\n",
        "    left = self._build_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
        "    right = self._build_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
        "    return Node(best_feature, best_threshold, left, right)\n",
        "\n",
        "  def _most_common_label(self, y):\n",
        "    unique_labels, counts = np.unique(y, return_counts=True)\n",
        "    return unique_labels[np.argmax(counts)]\n",
        "\n",
        "  def _split(self, X_column, split_threshold):\n",
        "    left_idxs = np.argwhere(X_column <= split_threshold).flatten()\n",
        "    right_idxs = np.argwhere(X_column > split_threshold).flatten()\n",
        "    return left_idxs, right_idxs\n",
        "\n",
        "  def _best_split(self, X, y):\n",
        "    best_gain, split_idx, split_threshold = float(\"inf\"), None, None\n",
        "\n",
        "    for feat_idx in range(X.shape[1]):\n",
        "      X_Column = X[:, feat_idx]\n",
        "      X_Column_sorted = np.sort(X_Column)\n",
        "      thresholds = (X_Column_sorted[:-1] + X_Column_sorted[1:])/2\n",
        "\n",
        "      for threshold in thresholds:\n",
        "        gain = self._information_gain(y, X_Column, threshold)\n",
        "\n",
        "        if gain < best_gain:\n",
        "          best_gain = gain\n",
        "          split_idx = feat_idx\n",
        "          split_threshold = threshold\n",
        "\n",
        "    return split_idx, split_threshold\n",
        "\n",
        "\n",
        "  def _information_gain(self, y, X_column, threshold):\n",
        "    left_idxs, right_idxs = self._split(X_column, threshold)\n",
        "\n",
        "    if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
        "      return 0\n",
        "\n",
        "    n, n_l, n_r = len(y), len(left_idxs), len(right_idxs)\n",
        "    e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
        "    information_gain = (n_l/n)*e_l + (n_r/n)*e_r\n",
        "    return information_gain\n",
        "  def _entropy(self, y):\n",
        "    fid3 = np.mean(y)\n",
        "\n",
        "    if fid3 == 0 or fid3 == 1: return 0\n",
        "    else: return -fid3 * np.log(fid3) - (1 - fid3) * np.log(1 - fid3)\n",
        "\n",
        "  def predict(self, X):\n",
        "    predictions = np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "    return predictions\n",
        "\n",
        "  def _traverse_tree(self, x, node):\n",
        "    if node.is_leaf_node():\n",
        "      return node.value\n",
        "\n",
        "    if x[node.feature] <= node.threshold:\n",
        "      return self._traverse_tree(x, node.left)\n",
        "    return self._traverse_tree(x, node.right)\n",
        "\n",
        "class AdaBoostWithTreeStump:\n",
        "    def __init__(self, n_estimators=50):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.alphas = []\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        weights = np.ones(m) / m\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            stump = DecisionTree(max_depth=1)\n",
        "            stump.fit(X, y)\n",
        "\n",
        "            predictions = stump.predict(X)\n",
        "            error = np.sum(predictions != y) / m\n",
        "\n",
        "            if error == 0:\n",
        "                alpha = 1e10\n",
        "            else:\n",
        "                alpha = 0.5 * np.log((1 - error) / error)\n",
        "\n",
        "            self.alphas.append(alpha)\n",
        "            self.models.append(stump)\n",
        "\n",
        "            new_weights = []\n",
        "            for i in range(m):\n",
        "                if predictions[i] == y[i]:\n",
        "                    new_weight = weights[i] * np.exp(-alpha)\n",
        "                else:\n",
        "                    new_weight = weights[i] * np.exp(alpha)\n",
        "                new_weights.append(new_weight)\n",
        "\n",
        "            min_weight = 1e-10\n",
        "            new_weights = [max(w, min_weight) for w in new_weights]\n",
        "            weight_sum = np.sum(new_weights)\n",
        "            weights = [w / weight_sum for w in new_weights]\n",
        "            # weights /= np.sum(weights)\n",
        "\n",
        "            cumulative_weights = np.cumsum(weights)\n",
        "\n",
        "            random_values = np.random.rand(m)\n",
        "\n",
        "            indices = np.searchsorted(cumulative_weights, random_values)\n",
        "            X, y = X[indices], y[indices]\n",
        "\n",
        "    def predict(self, X):\n",
        "        m = len(X)\n",
        "        final_predictions = np.zeros(m)\n",
        "\n",
        "        for alpha, model in zip(self.alphas, self.models):\n",
        "            predictions = model.predict(X)\n",
        "            final_predictions += alpha * predictions\n",
        "        return np.where(final_predictions > 0, 1, 0)\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Breast Cancer Dataset\n",
        "# data = load_breast_cancer()\n",
        "# X, y = data.data, data.target\n",
        "\n",
        "X = np.array([[1, 2],\n",
        "              [2, 3],\n",
        "              [3, 4],\n",
        "              [4, 5],\n",
        "              [5, 6]])\n",
        "y = np.array([1, 1, 0, 0, 0])\n",
        "\n",
        "clf = AdaBoostWithTreeStump(n_estimators=100)\n",
        "clf.fit(X, y)\n",
        "\n",
        "y_pred = clf.predict(X)\n",
        "\n",
        "def accuracy(y_test, y_pred):\n",
        "  return np.mean(y_test == y_pred)\n",
        "\n",
        "acc = accuracy(y, y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "HsltxK4ks4VX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e629df18-1b60-4c2b-b13a-7ff1235836f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    }
  ]
}